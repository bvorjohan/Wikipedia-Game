import tf-idf
import Scraper


beginning_url = "https://en.wikipedia.org/wiki/Trigonometry"
end_url = "https://en.wikipedia.org/wiki/Adolf_Hitler"


# obtain seed and target pages


# vectorize target, use in predictor

# for loop; max value = 20?
    # process body text in seed; make list of urls
    # for each url in list of urls:
        # obtain body text in url
        # vectorize body text
        # dot product into score
    # find max score in vector
    # store corresponding url in map tracker
    # pass new url into loop

#return stuff
